{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Retrieving all data from local SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>submission_redditID</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-12-28 04:32:27 UTC</td>\n",
       "      <td>nt6qa</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Hawks slam the Nets 106-70 in New Jersey for t...</td>\n",
       "      <td>www.reddit.com/r/AtlantaHawks/comments/nt6qa/h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-12-18 15:27:42 UTC</td>\n",
       "      <td>nhd05</td>\n",
       "      <td>ATL</td>\n",
       "      <td>This made me sad:  Why many NBA stars bypass A...</td>\n",
       "      <td>www.reddit.com/r/AtlantaHawks/comments/nhd05/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-12-16 19:26:26 UTC</td>\n",
       "      <td>nfh80</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Free scrimmage game tonight (12/16)</td>\n",
       "      <td>www.reddit.com/r/AtlantaHawks/comments/nfh80/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-12-14 03:45:24 UTC</td>\n",
       "      <td>nbxlw</td>\n",
       "      <td>ATL</td>\n",
       "      <td>fuck tmac</td>\n",
       "      <td>www.reddit.com/r/AtlantaHawks/comments/nbxlw/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-12-11 21:44:52 UTC</td>\n",
       "      <td>n8ufg</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Ruck Sund says Hawks don’t want to pay tax, ma...</td>\n",
       "      <td>www.reddit.com/r/AtlantaHawks/comments/n8ufg/r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp submission_redditID subreddit  \\\n",
       "0  2011-12-28 04:32:27 UTC               nt6qa       ATL   \n",
       "1  2011-12-18 15:27:42 UTC               nhd05       ATL   \n",
       "2  2011-12-16 19:26:26 UTC               nfh80       ATL   \n",
       "3  2011-12-14 03:45:24 UTC               nbxlw       ATL   \n",
       "4  2011-12-11 21:44:52 UTC               n8ufg       ATL   \n",
       "\n",
       "                                    submission_title  \\\n",
       "0  Hawks slam the Nets 106-70 in New Jersey for t...   \n",
       "1  This made me sad:  Why many NBA stars bypass A...   \n",
       "2                Free scrimmage game tonight (12/16)   \n",
       "3                                          fuck tmac   \n",
       "4  Ruck Sund says Hawks don’t want to pay tax, ma...   \n",
       "\n",
       "                                      submission_url  \n",
       "0  www.reddit.com/r/AtlantaHawks/comments/nt6qa/h...  \n",
       "1  www.reddit.com/r/AtlantaHawks/comments/nhd05/t...  \n",
       "2  www.reddit.com/r/AtlantaHawks/comments/nfh80/f...  \n",
       "3  www.reddit.com/r/AtlantaHawks/comments/nbxlw/f...  \n",
       "4  www.reddit.com/r/AtlantaHawks/comments/n8ufg/r...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting to sql database and storing data in 'reddit_data\n",
    "sql_db = 'reddit_db.sqlite'\n",
    "conn = sqlite3.connect(sql_db)\n",
    "cur = conn.cursor()\n",
    "\n",
    "#cur.execute('''SELECT NBA_submissions.date_created,NBA_submissions.submission_score,NBA_subs.sub_name,NBA_submissions.submission_title FROM NBA_submissions,NBA_subs WHERE NBA_submissions.team_id = NBA_subs.id''')\n",
    "#reddit_data = pd.DataFrame(data=cur.fetchall(),columns=['timestamp','submission_score','subreddit','submission_title'])\n",
    "\n",
    "\n",
    "\n",
    "query = '''SELECT NBA_submissions.date_created,NBA_submissions.sub_red_id,NBA_subs.team_name,NBA_submissions.submission_title,NBA_submissions.reddit_url FROM NBA_submissions,NBA_subs WHERE NBA_submissions.team_id = NBA_subs.id'''\n",
    "columns_list=['timestamp','submission_redditID','subreddit','submission_title','submission_url']\n",
    "\n",
    "cur.execute(query)\n",
    "reddit_data = pd.DataFrame(data=cur.fetchall(),columns=columns_list)\n",
    "\n",
    "reddit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#change timestamp column to datetime objects\n",
    "reddit_data['timestamp'] = reddit_data['timestamp'].apply(lambda x: pd.to_datetime(x.split()[0] + ' ' + x.split()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###contains NBA season start and end dates for each seasons offseason, regular season and playoffs\n",
    "###the end date is incremented by one day\n",
    "\n",
    "season_dates = {'2013': {'offseason' : ('06/21/2013','11/28/2013'),'reg_season':('11/29/2013','04/16/2014'),'playoffs':('04/19/2014','06/15/2014')}\n",
    ", \n",
    "'2014': {'offseason' : ('06/21/2014','11/28/2014'),'reg_season':('10/28/2014','04/15/2015'),'playoffs':('04/18/2015','06/16/2015')}\n",
    ",\n",
    "'2015': {'offseason' : ('06/17/2015','10/26/2015'),'reg_season':('10/27/2015','04/13/2016'),'playoffs':('04/16/2016','06/19/2016')} \n",
    ",\n",
    "'2016' : {'offseason' : ('06/20/2016','10/24/2016'),'reg_season':('10/25/2016','04/12/2017'),'playoffs':('04/15/2017','06/12/2017')}\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of subreddits: 31\n"
     ]
    }
   ],
   "source": [
    "###contains all subreddit names\n",
    "### should equal 30 teams + 1 for the NBA\n",
    "\n",
    "subreddit_list = list(reddit_data['subreddit'].unique())\n",
    "print('# of subreddits:',len(subreddit_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for extracting significant days of submissions will be defined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def significant_submissions(reddit_df):\n",
    "    '''\n",
    "    (pandas df) -> [list of tuples(date,top submission that day,submission id)]\n",
    "    \n",
    "    provided a df of reddit submissions for 1 particular subreddit over a given period of time.\n",
    "    will assert that for 'subr_name' field of df that there is only 1 unique value\n",
    "    \n",
    "    \n",
    "    from this dataframe group total submissions counts per hour and then get a list of\n",
    "    statistically significant spikes in post per hour.\n",
    "    From this list filter it to so it only has unique day dates.\n",
    "    \n",
    "    For each day date retrieve data on the top submission  for that day,including its submission id and title.\n",
    "    '''\n",
    "    \n",
    "    tot_postshour_df = reddit_df.groupby(pd.TimeGrouper(freq='H'))['subreddit'].count()\n",
    "    post_per_hour = tot_postshour_df.reset_index()['subreddit']\n",
    "    post_per_hour = post_per_hour[post_per_hour!=0]\n",
    "    \n",
    "    std_level = post_per_hour.std()*3\n",
    "    mean_level = post_per_hour.mean()\n",
    "    threshhold = round(mean_level + std_level)\n",
    "    \n",
    "    \n",
    "    top_significant_times = tot_postshour_df[tot_postshour_df>threshhold]\n",
    "    top_significant_times = top_significant_times.reset_index()\n",
    "    top_significant_times = top_significant_times.sort_values('subreddit',ascending=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #results\n",
    "    significant_times = []\n",
    "    \n",
    "    \n",
    "    for time in top_significant_times.values:\n",
    "        significant_times.append({'timestamp':time[0],'std_measure':time[1]/std_level})\n",
    "    \n",
    "\n",
    "    significant_results = []\n",
    "    for significant_date in significant_times:\n",
    "        \n",
    "        #within hour\n",
    "        start_time = significant_date['timestamp'].to_pydatetime()\n",
    "        end_time = start_time + timedelta(hours=1)\n",
    "        \n",
    "        start_day = start_time.strftime('%Y-%m-%d')\n",
    "        end_day = end_time.strftime('%Y-%m-%d')\n",
    "        \n",
    "        if start_day == end_day:\n",
    "            #search for dataframe for this day, then use df.between_time for posts within that hour.\n",
    "            #get sliced data that is either 1 day or 2 day\n",
    "            day_data = reddit_df[start_day]\n",
    "        else:\n",
    "            day_data = reddit_df[start_day:end_day]\n",
    "            \n",
    "        df_results = day_data.between_time(start_time.time(),end_time.time())\n",
    "        top_title = df_results.reset_index().sort_values('submission_redditID',ascending=False)\n",
    "        \n",
    "        \n",
    "        #start_time = start_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        #end_time = end_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        \n",
    "        #retriving submission with highest score\n",
    "        #top_title = reddit_df[start_time:end_time].sort_values('submission_score',ascending=False)['submission_title']\n",
    "        \n",
    "        \n",
    "        if len(top_title) > 0:\n",
    "            \n",
    "            significant_results.append({'timestamp':significant_date['timestamp'].strftime('%Y-%m-%d %H:%M:%S'),'std_measure':significant_date['std_measure'],'submission_title':top_title['submission_title'].iloc[0],'submission_redditID':top_title['submission_redditID'].iloc[0],'submission_url':top_title['submission_url'].iloc[0]})\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    #changing timestamp from timestamp object to string\n",
    "    for time in significant_times:\n",
    "        time['timestamp'] = time['timestamp'].strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return significant_results\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "def df_periodslicer(reddit_df,start_date,end_date='',team=''):\n",
    "    \n",
    "    '''\n",
    "    (pd.df,string,string,string) -> pd.df indexed by timestamp field\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    if end_date == '':\n",
    "        \n",
    "        return_df = reddit_data.set_index('timestamp')[start_date]\n",
    "    else:\n",
    "        return_df = reddit_data.set_index('timestamp')[start_date:end_date]\n",
    "    \n",
    "    if len(team) < 1:\n",
    "        return return_df\n",
    "    else:\n",
    "        return return_df[return_df['subreddit']==team]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlights_json = {}\n",
    "season_types = ['reg_season','playoffs','offseason']\n",
    "\n",
    "\n",
    "for year in season_dates:\n",
    "    year_val = year\n",
    "    year_data = {}\n",
    "    \n",
    "    for team in subreddit_list:\n",
    "        subreddit_name = team\n",
    "        team_data = {}\n",
    "        \n",
    "        for season_type in season_types:\n",
    "            \n",
    "            start_date = season_dates[year][season_type][0]\n",
    "            end_date = season_dates[year][season_type][1]\n",
    "            team_df = df_periodslicer(reddit_data,start_date,end_date,team)\n",
    "            team_data[season_type] = significant_submissions(team_df)\n",
    "        \n",
    "        \n",
    "        year_data[team] = team_data\n",
    "    \n",
    "    highlights_json[year_val] = year_data\n",
    "\n",
    "    \n",
    "len(highlights_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "for item in highlights_json['2015']['lakers']['reg_season']:\n",
    "    print(item['top_submission_title'])\n",
    "'''\n",
    "import json\n",
    "\n",
    "with open('significant_subs.json','w') as out:\n",
    "    json.dump(highlights_json,out)\n",
    "\n",
    "\n",
    "#highlights_json['2013']['atlantahawks']['reg_season'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
